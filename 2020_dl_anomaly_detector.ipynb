{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020_dl_anomaly_detector\n",
    "\n",
    "This is an experiment with deep learning for anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generators\n",
    "\n",
    "Regular data (label=0) will be random data with mean=0, std=1. Define functions that can transform random data into irregular data (label=1) with spikes and steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(data):\n",
    "    \n",
    "    for i, _ in enumerate(data):\n",
    "        step_point = math.abs(torch.randn(1)*(len(data[i]-1)))\n",
    "        for j, _ in enumerate(data[i][step_point:]):\n",
    "            data[i][j] = data[i][step_point]*math.abs(data[i]*10)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def spike(data):\n",
    "    pass\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Data with Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.randn(128, 256)\n",
    "valid_data = torch.randn(32, 256)\n",
    "test_data = torch.randn(32, 256)\n",
    "\n",
    "train_labels = torch.zeros([4, 32], dtype=torch.long)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 256]) tensor([[-0.1379, -1.0138,  1.8785,  ..., -1.1857, -0.3541, -0.1086],\n",
      "        [ 0.5040, -0.2387,  0.1149,  ...,  1.1716, -0.3794, -0.1792],\n",
      "        [-1.0497, -0.9718, -1.0531,  ...,  0.5633, -0.2969, -1.0968],\n",
      "        ...,\n",
      "        [ 1.2075,  0.3555, -0.3971,  ...,  0.5048,  0.6821, -0.2055],\n",
      "        [ 0.2666,  0.9436, -0.9972,  ..., -0.1488,  0.2987, -1.3979],\n",
      "        [ 0.4615, -0.0264,  0.7797,  ...,  0.0766, -0.2884,  0.5268]])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "print(dataiter.next().shape, dataiter.next())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.fc2 = nn.Linear(64, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        return F.softmax(self.fc2(x), dim=1)\n",
    "    \n",
    "model = Model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_funct = nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining loss: -0.4495577961206436\n",
      "Epoch: 2 \tTraining loss: -0.4565207287669182\n",
      "Epoch: 3 \tTraining loss: -0.46351412683725357\n",
      "Epoch: 4 \tTraining loss: -0.4705336168408394\n",
      "Epoch: 5 \tTraining loss: -0.4775726944208145\n",
      "Epoch: 6 \tTraining loss: -0.4846278354525566\n",
      "Epoch: 7 \tTraining loss: -0.491693452000618\n",
      "Epoch: 8 \tTraining loss: -0.4987645596265793\n",
      "Epoch: 9 \tTraining loss: -0.5058354288339615\n",
      "Epoch: 10 \tTraining loss: -0.5129006505012512\n",
      "Epoch: 11 \tTraining loss: -0.5199531614780426\n",
      "Epoch: 12 \tTraining loss: -0.5269887149333954\n",
      "Epoch: 13 \tTraining loss: -0.5340026319026947\n",
      "Epoch: 14 \tTraining loss: -0.5409897118806839\n",
      "Epoch: 15 \tTraining loss: -0.547945037484169\n",
      "Epoch: 16 \tTraining loss: -0.5548629909753799\n",
      "Epoch: 17 \tTraining loss: -0.5617390722036362\n",
      "Epoch: 18 \tTraining loss: -0.5685688257217407\n",
      "Epoch: 19 \tTraining loss: -0.5753477662801743\n",
      "Epoch: 20 \tTraining loss: -0.582070991396904\n",
      "Epoch: 21 \tTraining loss: -0.5887342989444733\n",
      "Epoch: 22 \tTraining loss: -0.5953344106674194\n",
      "Epoch: 23 \tTraining loss: -0.6018676310777664\n",
      "Epoch: 24 \tTraining loss: -0.6083302348852158\n",
      "Epoch: 25 \tTraining loss: -0.614719346165657\n",
      "Epoch: 26 \tTraining loss: -0.6210322827100754\n",
      "Epoch: 27 \tTraining loss: -0.6272664964199066\n",
      "Epoch: 28 \tTraining loss: -0.6334197670221329\n",
      "Epoch: 29 \tTraining loss: -0.6394894570112228\n",
      "Epoch: 30 \tTraining loss: -0.6454734802246094\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    label_iter = iter(train_labels)\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_losses = []\n",
    "    \n",
    "    for data in train_loader:\n",
    "        probs = model(data)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        labels = next(label_iter)\n",
    "        \n",
    "        #print(data.shape, labels.shape, train_labels.shape, len(train_labels))\n",
    "        \n",
    "        loss = error_funct(probs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    print(\"Epoch:\", e+1, \"\\tTraining loss:\", train_loss) #, \"\\tValidation loss:\", valid_loss)\n",
    "        \n",
    "        \n",
    "    #for valid_data in valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
