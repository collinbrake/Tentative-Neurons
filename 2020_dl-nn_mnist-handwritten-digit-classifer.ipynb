{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020_dl-nn_mnist-handwritten-digit-classifer\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This is a deep neural network that I am building from my notes from this class: [Udacity - Intro to Deep Learning with Pytorch](https://classroom.udacity.com/courses/ud188/lessons/c5706f76-0e30-4b48-b74e-c19fafc33a75/concepts/0d735345-f080-49c4-8fbf-a68012923f50). I want to reinforce what I learned from Lessons 4 and 5 by building a complete (basic) network using only my notes and the Pytorch documentation as references.\n",
    "\n",
    "## Plan\n",
    "\n",
    "- Transform and load MNIST handwritten digits data\n",
    "- Define a neural network class\n",
    "- Select an error function and optimizer for the network\n",
    "- Train the model with validation\n",
    "  - Print training and testing loss each epoch\n",
    "  - Graph?\n",
    "- Save the model\n",
    "- Load the model from file\n",
    "- Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_data = datasets.MNIST(\"./2020_data_mnist\", train=True, transform=transform, download=True)\n",
    "test_data = datasets.MNIST(\"./2020_data_mnist\", train=False, transform=transform, download=False)\n",
    "\n",
    "# Percent of training data to split off for validation\n",
    "valid_size = 0.2\n",
    "\n",
    "data_len = len(train_data)\n",
    "indices = list(range(data_len))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * data_len))\n",
    "valid_indices, train_indices = indices[:split], indices[split:]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=64, sampler=valid_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
